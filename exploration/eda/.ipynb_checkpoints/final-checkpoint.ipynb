{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarise all the steps done since now\n",
    "# 1. load the data\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('../../data/raw/UJIndoorLoc/trainingData.csv')\n",
    "valid = pd.read_csv('../../data/raw/UJIndoorLoc/validationData.csv')\n",
    "wap_names = data.iloc[:,:520].columns\n",
    "\n",
    "# 2. transform the values from 100dBm to -105dBm\n",
    "data[wap_names] = data[wap_names].replace(to_replace=100, value=-105)\n",
    "valid[wap_names] = valid[wap_names].replace(to_replace=100, value=-105)\n",
    "\n",
    "\n",
    "# 3. Normalize the waps by row by min and max\n",
    "norm_df = data.copy()\n",
    "norm_valid = valid.copy()\n",
    "\n",
    "norm_df[wap_names] = norm_df[wap_names].apply(lambda x: (x - x.min())/(x.max() - x.min()), axis='columns', result_type='expand')\n",
    "norm_df['id'] = str(norm_df.index + 1)\n",
    "norm_df_clean = norm_df.dropna() # missing values are created in 76 rows, as they have 0 variance (further exploration)\n",
    "norm_valid[wap_names] = norm_valid[wap_names].apply(lambda x: (x - x.min())/(x.max() - x.min()), axis='columns', result_type='expand')\n",
    "\n",
    "\n",
    "# 4. Store results\n",
    "norm_df.to_csv('../../data/clean/norm_training.csv')\n",
    "norm_valid.to_csv('../../data/clean/norm_validation.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
