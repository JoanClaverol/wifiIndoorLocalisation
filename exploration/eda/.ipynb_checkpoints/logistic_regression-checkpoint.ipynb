{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BUILDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "def postResample_class(y_true, y_preds):\n",
    "    \"\"\"\n",
    "    Given a vector with true results and the predictions of the model, \n",
    "    returns the confusion matrix, accuracy, kappa and a report(recall and recap) as a list. \n",
    "    \"\"\"    \n",
    "    # check the metrics with a confusion matrix\n",
    "    confusion_matrix = pd.crosstab(y_true, y_preds, rownames=['Real'], colnames=['Pred'])\n",
    "    print(confusion_matrix)\n",
    "    print('')\n",
    "\n",
    "    # print the accuracy\n",
    "    accuracy = sum(1 for x,y in zip(y_preds, y_true) if x == y) / len(y_true)\n",
    "    print(\"The accuracy of that model is: \", round(accuracy,4))\n",
    "\n",
    "    # kappa \n",
    "    kappa = cohen_kappa_score(y1 = y_true, y2 = y_preds)\n",
    "    print('The kappa of that model is: ', round(kappa,4))\n",
    "    print('')\n",
    "\n",
    "    # recall and recap\n",
    "    report = classification_report(y_true=y_true, y_pred=y_preds) \n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('../../data/raw/UJIndoorLoc/trainingData.csv')\n",
    "valid = pd.read_csv('../../data/raw/UJIndoorLoc/validationData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "wap_names = data.iloc[:,:520].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_check(temp_data, temp_valid):\n",
    "\n",
    "    # train and test\n",
    "    train, test = train_test_split(temp_data, train_size=0.80, random_state=42)\n",
    "\n",
    "    logReg = LogisticRegression()\n",
    "    logReg.fit(train[wap_names], train['BUILDINGID'])\n",
    "\n",
    "    # check the results\n",
    "    results = postResample_class(\n",
    "        y_preds=logReg.predict(test[wap_names]), y_true=test['BUILDINGID']\n",
    "    )\n",
    "    # check the results\n",
    "    results = postResample_class(\n",
    "        y_preds=logReg.predict(temp_valid[wap_names]), y_true=temp_valid['BUILDINGID']\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No pre process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred     0     1     2\n",
      "Real                  \n",
      "0     1078     0     0\n",
      "1        0  1001     0\n",
      "2        0     8  1901\n",
      "\n",
      "The accuracy of that model is:  0.998\n",
      "The kappa of that model is:  0.9968\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1078\n",
      "           1       0.99      1.00      1.00      1001\n",
      "           2       1.00      1.00      1.00      1909\n",
      "\n",
      "    accuracy                           1.00      3988\n",
      "   macro avg       1.00      1.00      1.00      3988\n",
      "weighted avg       1.00      1.00      1.00      3988\n",
      "\n",
      "Pred    0    1    2\n",
      "Real               \n",
      "0     536    0    0\n",
      "1       0  306    1\n",
      "2       0    0  268\n",
      "\n",
      "The accuracy of that model is:  0.9991\n",
      "The kappa of that model is:  0.9986\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       536\n",
      "           1       1.00      1.00      1.00       307\n",
      "           2       1.00      1.00      1.00       268\n",
      "\n",
      "    accuracy                           1.00      1111\n",
      "   macro avg       1.00      1.00      1.00      1111\n",
      "weighted avg       1.00      1.00      1.00      1111\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joan/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train and test\n",
    "train, test = train_test_split(data, train_size=0.80, random_state=42)\n",
    "\n",
    "logReg = LogisticRegression()\n",
    "logReg.fit(train[wap_names], train['BUILDINGID'])\n",
    "\n",
    "# check the results\n",
    "results = postResample_class(\n",
    "    y_preds=logReg.predict(test[wap_names]), y_true=test['BUILDINGID']\n",
    ")\n",
    "# check the results\n",
    "results = postResample_class(\n",
    "    y_preds=logReg.predict(valid[wap_names]), y_true=valid['BUILDINGID']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dbm value changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[wap_names] = data[wap_names].replace(to_replace=100, value=-105)\n",
    "valid[wap_names] = valid[wap_names].replace(to_replace=100, value=-105)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred     0     1     2\n",
      "Real                  \n",
      "0     1078     0     0\n",
      "1        0  1001     0\n",
      "2        0     8  1901\n",
      "\n",
      "The accuracy of that model is:  0.998\n",
      "The kappa of that model is:  0.9968\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1078\n",
      "           1       0.99      1.00      1.00      1001\n",
      "           2       1.00      1.00      1.00      1909\n",
      "\n",
      "    accuracy                           1.00      3988\n",
      "   macro avg       1.00      1.00      1.00      3988\n",
      "weighted avg       1.00      1.00      1.00      3988\n",
      "\n",
      "Pred    0    1    2\n",
      "Real               \n",
      "0     535    1    0\n",
      "1       0  307    0\n",
      "2       0    0  268\n",
      "\n",
      "The accuracy of that model is:  0.9991\n",
      "The kappa of that model is:  0.9986\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       536\n",
      "           1       1.00      1.00      1.00       307\n",
      "           2       1.00      1.00      1.00       268\n",
      "\n",
      "    accuracy                           1.00      1111\n",
      "   macro avg       1.00      1.00      1.00      1111\n",
      "weighted avg       1.00      1.00      1.00      1111\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joan/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "model_check(temp_data=data, temp_valid=valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Min and max normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_df = data.copy()\n",
    "norm_valid = valid.copy()\n",
    "\n",
    "norm_df[wap_names] = norm_df[wap_names].apply(lambda x: (x - x.min())/(x.max() - x.min()), axis='columns', result_type='expand')\n",
    "norm_valid[wap_names] = norm_valid[wap_names].apply(lambda x: (x - x.min())/(x.max() - x.min()), axis='columns', result_type='expand')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing missing values, by finding out the missing values\n",
    "norm_df['id'] = norm_df.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_df_clean = norm_df.dropna()\n",
    "norm_valid_clean = norm_valid.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(norm_valid) - len(norm_valid_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(norm_df) - len(norm_df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred     0     1     2\n",
      "Real                  \n",
      "0     1049     0     0\n",
      "1        0  1021     0\n",
      "2        0     0  1903\n",
      "\n",
      "The accuracy of that model is:  1.0\n",
      "The kappa of that model is:  1.0\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1049\n",
      "           1       1.00      1.00      1.00      1021\n",
      "           2       1.00      1.00      1.00      1903\n",
      "\n",
      "    accuracy                           1.00      3973\n",
      "   macro avg       1.00      1.00      1.00      3973\n",
      "weighted avg       1.00      1.00      1.00      3973\n",
      "\n",
      "Pred    0    1    2\n",
      "Real               \n",
      "0     536    0    0\n",
      "1       0  307    0\n",
      "2       0    0  268\n",
      "\n",
      "The accuracy of that model is:  1.0\n",
      "The kappa of that model is:  1.0\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       536\n",
      "           1       1.00      1.00      1.00       307\n",
      "           2       1.00      1.00      1.00       268\n",
      "\n",
      "    accuracy                           1.00      1111\n",
      "   macro avg       1.00      1.00      1.00      1111\n",
      "weighted avg       1.00      1.00      1.00      1111\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_check(temp_data=norm_df_clean, temp_valid=norm_valid_clean)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
